# EDA_Web_App_Streamlit.py
"""
Streamlit app: Exploratory Data Analysis (EDA) for domain-specific datasets
Domains: E-commerce, Retail, Manufacturing

How to use:
1. Install dependencies: pip install streamlit pandas numpy plotly scikit-learn
2. Run: streamlit run EDA_Web_App_Streamlit.py
3. Upload a CSV or choose a sample dataset for each domain.

This single-file app generates domain-aware EDA including:
- Overview & data quality
- Numeric & categorical summaries
- Time-series sales analysis (if date + sales columns exist)
- Top products/customers
- Correlation heatmap
- Pivotable tables and downloadable reports

Author: Generated by ChatGPT
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO
from sklearn.preprocessing import LabelEncoder
import textwrap

st.set_page_config(page_title="Domain EDA — E-commerce / Retail / Manufacturing", layout="wide")

# --------------------------- Utilities ---------------------------

def generate_sample_ecommerce(n=2000, seed=42):
    np.random.seed(seed)
    customers = [f'CUST_{i:05d}' for i in np.random.randint(1, 800, size=n)]
    products = [f'PROD_{i:04d}' for i in np.random.randint(1, 200, size=n)]
    categories = np.random.choice(['Clothing','Electronics','Home','Beauty','Sports'], size=n, p=[0.25,0.2,0.25,0.15,0.15])
    prices = np.round(np.random.exponential(scale=50, size=n) + np.random.randint(5,500,size=n),2)
    quantities = np.random.randint(1,5,size=n)
    order_dates = pd.to_datetime('2024-01-01') + pd.to_timedelta(np.random.randint(0,365,size=n), unit='d')
    order_ids = [f'ORD_{i:07d}' for i in range(100000, 100000+n)]
    df = pd.DataFrame({
        'order_id': order_ids,
        'order_date': order_dates,
        'customer_id': customers,
        'product_id': products,
        'category': categories,
        'price': prices,
        'quantity': quantities
    })
    df['sales'] = (df['price'] * df['quantity']).round(2)
    return df


def generate_sample_retail(n=1500, seed=24):
    np.random.seed(seed)
    stores = [f'STORE_{i}' for i in np.random.randint(1,50,size=n)]
    skus = [f'SKU_{i:04d}' for i in np.random.randint(1,300,size=n)]
    dates = pd.to_datetime('2024-01-01') + pd.to_timedelta(np.random.randint(0,365,size=n), unit='d')
    prices = np.round(np.random.uniform(10,200, size=n),2)
    qty = np.random.randint(1,20,size=n)
    promos = np.random.choice([0,1], size=n, p=[0.8,0.2])
    df = pd.DataFrame({'store_id': stores, 'date': dates, 'sku': skus, 'price': prices, 'qty': qty, 'promo_flag':promos})
    df['revenue'] = (df['price'] * df['qty']).round(2)
    df['cost'] = (df['price'] * np.random.uniform(0.5,0.85,size=n) * df['qty']).round(2)
    return df


def generate_sample_manufacturing(n=1200, seed=7):
    np.random.seed(seed)
    machine_ids = [f'MACH_{i:03d}' for i in np.random.randint(1,30,size=n)]
    product_lines = np.random.choice(['Line-A','Line-B','Line-C'], size=n, p=[0.5,0.3,0.2])
    shift = np.random.choice(['Morning','Evening','Night'], size=n, p=[0.4,0.4,0.2])
    produced = np.random.randint(50,500,size=n)
    defective = (produced * np.random.beta(1,40,size=n)).astype(int)
    run_date = pd.to_datetime('2024-01-01') + pd.to_timedelta(np.random.randint(0,365,size=n), unit='d')
    cycle_time = np.round(np.random.normal(loc=60, scale=10, size=n),2)  # seconds
    df = pd.DataFrame({'machine_id':machine_ids,'product_line':product_lines,'shift':shift,'produced_qty':produced,'defective_qty':defective,'run_date':run_date,'cycle_time_s':cycle_time})
    df['yield_pct'] = ((df['produced_qty'] - df['defective_qty']) / df['produced_qty'] * 100).round(2)
    return df


def detect_date_cols(df):
    date_cols = []
    for c in df.columns:
        if np.issubdtype(df[c].dtype, np.datetime64):
            date_cols.append(c)
        else:
            # try parse
            try:
                _ = pd.to_datetime(df[c], errors='coerce')
                if _.notna().sum() / len(_) > 0.5:
                    date_cols.append(c)
            except Exception:
                pass
    return date_cols


def numeric_cats(df):
    nums = df.select_dtypes(include=['number']).columns.tolist()
    cats = df.select_dtypes(include=['object','category','bool']).columns.tolist()
    return nums, cats


# --------------------------- EDA functions ---------------------------

def overview(df):
    st.subheader('Data Overview & Quality')
    c1,c2,c3 = st.columns([1,1,2])
    with c1:
        st.metric('Rows', df.shape[0])
    with c2:
        st.metric('Columns', df.shape[1])
    with c3:
        missing = df.isna().mean().round(3)
        top_missing = missing[missing>0].sort_values(ascending=False)
        if len(top_missing)>0:
            st.write('Columns with missing values:')
            st.table(top_missing.head(10))
        else:
            st.write('No missing values detected (or very few).')
    st.write('---')
    st.dataframe(df.head(100))


def numeric_summary(df):
    nums, cats = numeric_cats(df)
    if not nums:
        st.info('No numeric columns detected for numeric summary.')
        return
    st.subheader('Numeric Summary')
    desc = df[nums].describe().T
    st.dataframe(desc)
    st.write('Distribution plots')
    for col in nums:
        fig = px.histogram(df, x=col, marginal='box', nbins=50, title=f'Histogram of {col}')
        st.plotly_chart(fig, use_container_width=True)


def categorical_summary(df):
    nums, cats = numeric_cats(df)
    if not cats:
        st.info('No categorical columns detected for categorical summary.')
        return
    st.subheader('Categorical Summary')
    for col in cats:
        counts = df[col].value_counts().nlargest(20)
        fig = px.bar(x=counts.index.astype(str), y=counts.values, title=f'Counts for {col}', labels={'x':col,'y':'count'})
        st.plotly_chart(fig, use_container_width=True)


def correlation_heatmap(df):
    nums, _ = numeric_cats(df)
    if len(nums) < 2:
        st.info('Need at least two numeric columns for correlation heatmap.')
        return
    corr = df[nums].corr()
    fig = px.imshow(corr, text_auto=True, title='Correlation matrix')
    st.plotly_chart(fig, use_container_width=True)


def time_series_analysis(df, date_col_candidates=None):
    st.subheader('Time-series analysis')
    if date_col_candidates is None:
        date_col_candidates = detect_date_cols(df)
    if not date_col_candidates:
        st.info('No date-like column found')
        return
    date_col = st.selectbox('Choose date column', date_col_candidates)
    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
    agg_choice = st.selectbox('Aggregate metric', ['sales','revenue','qty','produced_qty','revenue_sum'], key='aggchoice')
    # find candidate metric
    metric = None
    for m in ['sales','revenue','qty','quantity','produced_qty','revenue_sum']:
        if m in df.columns:
            metric = m
            break
    if metric is None:
        # fallback to numeric column with highest variance
        nums,_ = numeric_cats(df)
        if not nums:
            st.info('No numeric column to aggregate')
            return
        metric = max(nums, key=lambda c: df[c].var())
    st.write(f'Using metric: **{metric}**')
    res = df.groupby(pd.Grouper(key=date_col, freq='W'))[metric].sum().reset_index()
    fig = px.line(res, x=date_col, y=metric, title=f'Time series of {metric} (weekly)')
    st.plotly_chart(fig, use_container_width=True)


def top_n_analysis(df):
    st.subheader('Top N analysis')
    potential_groups = ['product_id','sku','category','customer_id','store_id','machine_id']
    groups = [g for g in potential_groups if g in df.columns]
    if not groups:
        st.info('No familiar grouping column found for top-N analysis')
        return
    g = st.selectbox('Group by', groups)
    metric = st.selectbox('Metric', [c for c in df.select_dtypes(include=['number']).columns.tolist()]+['sales','revenue'], index=0)
    dfg = df.groupby(g)[metric].sum().sort_values(ascending=False).reset_index()
    topn = st.slider('Top N', 5, 50, 10)
    fig = px.bar(dfg.head(topn), x=g, y=metric, title=f'Top {topn} {g} by {metric}')
    st.plotly_chart(fig, use_container_width=True)
    st.dataframe(dfg.head(200))


def manufacturing_quality(df):
    st.subheader('Manufacturing quality & OEE-like metrics')
    if 'produced_qty' in df.columns and 'defective_qty' in df.columns:
        df['good_qty'] = df['produced_qty'] - df['defective_qty']
        summary = df.groupby('machine_id').agg(total_produced=('produced_qty','sum'), total_defects=('defective_qty','sum'))
        summary['defect_rate_pct'] = (summary['total_defects']/summary['total_produced']*100).round(2)
        st.dataframe(summary.sort_values('defect_rate_pct').head(50))
        fig = px.histogram(summary, x='defect_rate_pct', nbins=40, title='Distribution of defect rate (%) by machine')
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info('Produced / defective columns not found — manufacturing specific analysis skipped.')


def download_df_as_csv(df):
    buf = BytesIO()
    df.to_csv(buf, index=False)
    buf.seek(0)
    return buf


# --------------------------- App layout ---------------------------

st.title('Domain-specific EDA (E-commerce | Retail | Manufacturing)')
st.write('Upload your dataset (CSV) or choose a built-in sample. The app will try to detect domain-specific columns and run appropriate EDA.')

with st.sidebar:
    st.header('Controls')
    domain = st.selectbox('Choose domain (affects sample data & domain-specific checks)', ['Auto-detect','E-commerce','Retail','Manufacturing'])
    use_sample = st.checkbox('Use sample dataset', value=True)
    uploaded_file = st.file_uploader('Or upload CSV', type=['csv'])
    st.markdown('---')
    st.write('Export')
    export_sample = st.button('Download current preview as CSV')


# Load data
if use_sample and uploaded_file is None:
    if domain == 'E-commerce':
        df = generate_sample_ecommerce()
    elif domain == 'Retail':
        df = generate_sample_retail()
    elif domain == 'Manufacturing':
        df = generate_sample_manufacturing()
    else:
        # Auto sample - show a small mix and let user pick
        st.sidebar.write('Auto sample chosen — pick one below')
        sample_choice = st.sidebar.radio('Sample dataset', ['E-commerce','Retail','Manufacturing'])
        if sample_choice == 'E-commerce':
            df = generate_sample_ecommerce()
        elif sample_choice == 'Retail':
            df = generate_sample_retail()
        else:
            df = generate_sample_manufacturing()
else:
    if uploaded_file is not None:
        try:
            df = pd.read_csv(uploaded_file)
        except Exception:
            df = pd.read_csv(uploaded_file, encoding='latin-1')
    else:
        # fallback
        st.warning('No file uploaded and sample disabled — loading e-commerce sample by default')
        df = generate_sample_ecommerce()

# Show dataset name and a quick peek
st.sidebar.write('Dataset preview:')
st.sidebar.dataframe(df.head(10))

# Main EDA
overview(df)

cols = df.columns.tolist()

# Domain specific analysis
if domain == 'Auto-detect' or domain == 'Auto-detect' and 'order_id' in cols:
    # auto heuristic
    if any(x in cols for x in ['order_id','order_date','customer_id','product_id','sales']):
        detected_domain = 'E-commerce'
    elif any(x in cols for x in ['store_id','sku','revenue']):
        detected_domain = 'Retail'
    elif any(x in cols for x in ['machine_id','produced_qty']):
        detected_domain = 'Manufacturing'
    else:
        detected_domain = domain
else:
    detected_domain = domain

st.info(f'Detected / chosen domain: **{detected_domain}**')

numeric_summary(df)
categorical_summary(df)
correlation_heatmap(df)

# Domain-specific sections
if detected_domain == 'E-commerce' or detected_domain == 'Auto-detect' and any(x in cols for x in ['order_id','order_date']):
    st.markdown('### E-commerce specific')
    time_series_analysis(df)
    top_n_analysis(df)

if detected_domain == 'Retail' or detected_domain == 'Auto-detect' and any(x in cols for x in ['store_id','sku']):
    st.markdown('### Retail specific')
    time_series_analysis(df)
    top_n_analysis(df)

if detected_domain == 'Manufacturing' or detected_domain == 'Auto-detect' and any(x in cols for x in ['produced_qty','machine_id']):
    st.markdown('### Manufacturing specific')
    manufacturing_quality(df)
    time_series_analysis(df)

# Quick pivot / groupby explorer
st.subheader('Pivot / Group-by Explorer')
with st.expander('Create custom pivot'):
    group_cols = st.multiselect('Group by', cols, default=[c for c in cols if c in ['category','product_id','store_id','machine_id','customer_id']][:2])
    agg_col = st.selectbox('Aggregate column', [None]+cols)
    agg_func = st.selectbox('Agg function', ['sum','mean','count','median','min','max'])
    if st.button('Generate pivot'):
        if not group_cols or agg_col is None:
            st.warning('Choose group_by columns and aggregate column')
        else:
            pg = df.groupby(group_cols)[agg_col].agg(agg_func).reset_index()
            st.dataframe(pg)

# Download
if 'export_sample' in locals() and export_sample:
    buf = download_df_as_csv(df)
    st.sidebar.download_button('Download CSV', buf, file_name='export_preview.csv')

st.markdown('---')
st.write('Notes: This app is purposefully generic — for production-ready EDA, you may want to connect to your databases, add authentication, caching, and domain-specific KPIs (e.g., AOV, CLTV, Churn for e-commerce; Shrinkage, Stockouts for retail; OEE, MTBF for manufacturing).')

st.caption('Made with Streamlit — edit the single file to customize behaviors and visuals.')
